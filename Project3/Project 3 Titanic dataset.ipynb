{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Titanic survival dataset\n",
    "----\n",
    "In this notebook, we explore some common ML models to guess wheather a person can survive in the tragic Titanic accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics, model_selection, svm, preprocessing, ensemble, neighbors, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>nan</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Appleton</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Artagaveytia</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>nan</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived          name     sex      age  sibsp  parch    ticket  \\\n",
       "0     1.0       1.0         Allen  female  29.0000    0.0    0.0     24160   \n",
       "1     1.0       1.0       Allison    male   0.9167    1.0    2.0    113781   \n",
       "2     1.0       0.0       Allison  female   2.0000    1.0    2.0    113781   \n",
       "3     1.0       0.0       Allison    male  30.0000    1.0    2.0    113781   \n",
       "4     1.0       0.0       Allison  female  25.0000    1.0    2.0    113781   \n",
       "5     1.0       1.0      Anderson    male  48.0000    0.0    0.0     19952   \n",
       "6     1.0       1.0       Andrews  female  63.0000    1.0    0.0     13502   \n",
       "7     1.0       0.0       Andrews    male  39.0000    0.0    0.0    112050   \n",
       "8     1.0       1.0      Appleton  female  53.0000    2.0    0.0     11769   \n",
       "9     1.0       0.0  Artagaveytia    male  71.0000    0.0    0.0  PC 17609   \n",
       "\n",
       "       fare    cabin embarked boat   body  \n",
       "0  211.3375       B5        S    2    0.0  \n",
       "1  151.5500  C22 C26        S   11    0.0  \n",
       "2  151.5500  C22 C26        S  nan    0.0  \n",
       "3  151.5500  C22 C26        S  nan  135.0  \n",
       "4  151.5500  C22 C26        S  nan    0.0  \n",
       "5   26.5500      E12        S    3    0.0  \n",
       "6   77.9583       D7        S   10    0.0  \n",
       "7    0.0000      A36        S  nan    0.0  \n",
       "8   51.4792     C101        S    D    0.0  \n",
       "9   49.5042      nan        C  nan   22.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training set\n",
    "df = pd.read_csv('./titanicTrain.csv')\n",
    "\n",
    "# drop rows that is all nan\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# convert name in to the first name\n",
    "df.name = df.name.apply(lambda x: x.split(sep=',')[0])\n",
    "\n",
    "# fill nan with default valuus\n",
    "df.age = df.age.fillna(value=0)\n",
    "df.cabin = df.cabin.fillna(value='nan')\n",
    "df.embarked = df.embarked.fillna(value='nan')\n",
    "df.boat = df.boat.fillna(value='nan')\n",
    "df.body = df.body.fillna(value=0)\n",
    "df = df.drop('home.dest', axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McCormack</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367228</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McCoy</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>367226</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McCoy</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>367226</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McCoy</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>367226</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McDermott</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330932</td>\n",
       "      <td>7.7875</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McEvoy</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36568</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McGovern</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330931</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McGowan</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McGowan</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9232</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>McMahon</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370372</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>nan</td>\n",
       "      <td>Q</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived       name     sex   age  sibsp  parch  ticket     fare  \\\n",
       "0       3       NaN  McCormack    male   0.0      0      0  367228   7.7500   \n",
       "1       3       NaN      McCoy  female   0.0      2      0  367226  23.2500   \n",
       "2       3       NaN      McCoy  female   0.0      2      0  367226  23.2500   \n",
       "3       3       NaN      McCoy    male   0.0      2      0  367226  23.2500   \n",
       "4       3       NaN  McDermott  female   0.0      0      0  330932   7.7875   \n",
       "5       3       NaN     McEvoy    male   0.0      0      0   36568  15.5000   \n",
       "6       3       NaN   McGovern  female   0.0      0      0  330931   7.8792   \n",
       "7       3       NaN    McGowan  female  15.0      0      0  330923   8.0292   \n",
       "8       3       NaN    McGowan  female  35.0      0      0    9232   7.7500   \n",
       "9       3       NaN    McMahon    male   0.0      0      0  370372   7.7500   \n",
       "\n",
       "  cabin embarked boat  body  \n",
       "0   nan        Q  nan   0.0  \n",
       "1   nan        Q   16   0.0  \n",
       "2   nan        Q   16   0.0  \n",
       "3   nan        Q   16   0.0  \n",
       "4   nan        Q   13   0.0  \n",
       "5   nan        Q  nan   0.0  \n",
       "6   nan        Q   13   0.0  \n",
       "7   nan        Q  nan   0.0  \n",
       "8   nan        Q  nan   0.0  \n",
       "9   nan        Q  nan   0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load testing set\n",
    "test = pd.read_csv('titanicQuestion.csv')\n",
    "# drop nan\n",
    "test = test.dropna(how='all')\n",
    "# convert name to first name\n",
    "test.name = test.name.apply(lambda x: x.split(sep=',')[0])\n",
    "# fill nan\n",
    "test.age = test.age.fillna(value=0)\n",
    "test.cabin = test.cabin.fillna(value='nan')\n",
    "test.embarked = test.embarked.fillna(value='nan')\n",
    "test.boat = test.boat.fillna(value='nan')\n",
    "test.body = test.body.fillna(value=0)\n",
    "# only one nan in fare\n",
    "test.fare = test.fare.fillna(value=0)\n",
    "test = test.drop('home.dest', axis=1)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answers (Y in training set)\n",
    "Y = df.survived.values\n",
    "\n",
    "data = df.drop(['survived'], axis=1).values\n",
    "test_data = test.drop(['survived'], axis=1).values\n",
    "all_data = np.concatenate((test_data, data))\n",
    "\n",
    "# categorize name, gender, ticket, cabin, embarked, boat, body data\n",
    "# e.g. male => 1, female => 0\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in [1,2,6,8,9,10,11]:\n",
    "    le.fit(all_data[:, i])\n",
    "    data[:, i] = le.transform(data[:, i])\n",
    "    test_data[:, i] = le.transform(test_data[:, i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate different ML models:\n",
    "use 5-fold validation to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.713874146854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.09056473,  0.05454183,  0.05904222,  0.07654834,  0.07355332]),\n",
       " 'score_time': array([ 0.04002762,  0.03802395,  0.01250768,  0.0060041 ,  0.00100207]),\n",
       " 'test_score': array([ 0.59701493,  0.88059701,  0.74      ,  0.87437186,  0.47738693]),\n",
       " 'train_score': array([ 0.46808511,  0.87234043,  0.7225    ,  0.81772784,  0.63420724])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM classifier:\n",
    "# result: unable to predict well\n",
    "# possible reason: too much not continuous categorical data\n",
    "LSVM = svm.LinearSVC()\n",
    "result_LSVM = model_selection.cross_validate(LSVM, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_LSVM['test_score'].mean())\n",
    "result_LSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.577001550039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.08005643,  0.06554556,  0.06905174,  0.11007786,  0.10307193]),\n",
       " 'score_time': array([ 0.01951289,  0.01351142,  0.01300955,  0.01901412,  0.02051473]),\n",
       " 'test_score': array([ 0.5721393 ,  0.58208955,  0.575     ,  0.57286432,  0.58291457]),\n",
       " 'train_score': array([ 1.,  1.,  1.,  1.,  1.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-linear SVM classifier:\n",
    "# result: overfitting on training set (100% acc)\n",
    "SVM = svm.SVC()\n",
    "result_SVM = model_selection.cross_validate(SVM, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_SVM['test_score'].mean())\n",
    "result_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.580006975174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.01100612,  0.00898647,  0.01100683,  0.01348948,  0.0030005 ]),\n",
       " 'score_time': array([ 0.01000714,  0.02701998,  0.01200819,  0.00300241,  0.00200605]),\n",
       " 'test_score': array([ 0.62686567,  0.56716418,  0.505     ,  0.55778894,  0.64321608]),\n",
       " 'train_score': array([ 0.73216521,  0.52315394,  0.535     ,  0.66167291,  0.69787765])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent:\n",
    "# similar to linear SVM but with better optimizer (SGD)\n",
    "# result: fail to predict well\n",
    "# possible reason: too much not continuous categorical data\n",
    "SGD = linear_model.SGDClassifier()\n",
    "result_SGD = model_selection.cross_validate(SGD, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_SGD['test_score'].mean())\n",
    "result_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.973969499237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.02149534,  0.02101564,  0.02051568,  0.0220139 ,  0.02251697]),\n",
       " 'score_time': array([ 0.00200129,  0.00200152,  0.00200081,  0.00200415,  0.00200129]),\n",
       " 'test_score': array([ 0.99004975,  0.97512438,  0.97      ,  0.97487437,  0.95979899]),\n",
       " 'train_score': array([ 0.99749687,  1.        ,  0.99625   ,  0.99875156,  0.99500624])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest:\n",
    "# ensemble model using mutiple decision tree for classification\n",
    "# perform pretty well\n",
    "RF = ensemble.RandomForestClassifier(random_state=9487)\n",
    "result_RF = model_selection.cross_validate(RF, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_RF['test_score'].mean())\n",
    "result_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.923928598215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.00550437,  0.00400376,  0.00500202,  0.00500083,  0.00400186]),\n",
       " 'score_time': array([ 0.00150061,  0.00100064,  0.00100064,  0.00100255,  0.00100183]),\n",
       " 'test_score': array([ 0.96517413,  0.93034826,  0.9       ,  0.91959799,  0.90452261]),\n",
       " 'train_score': array([ 1.,  1.,  1.,  1.,  1.])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree:\n",
    "# perform well for a single model\n",
    "# probably make most decision respect to the boat variable\n",
    "Tree = tree.DecisionTreeClassifier(random_state=9487)\n",
    "result_Tree = model_selection.cross_validate(Tree, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_Tree['test_score'].mean())\n",
    "result_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation acc: 0.966944323608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.12910986,  0.18512845,  0.15761113,  0.1656158 ,  0.17862725]),\n",
       " 'score_time': array([ 0.00748515,  0.01301003,  0.01251054,  0.00902462,  0.00950837]),\n",
       " 'test_score': array([ 0.9800995 ,  0.9800995 ,  0.97      ,  0.96482412,  0.93969849]),\n",
       " 'train_score': array([ 0.98748436,  0.98623279,  0.99      ,  0.99001248,  0.99625468])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost classifier:\n",
    "# use 50 decision trees to deal with most difficult entries in the training set\n",
    "# use AdaBoost algorithm for optimizer\n",
    "AB = ensemble.AdaBoostClassifier(random_state=9487)\n",
    "result_AB = model_selection.cross_validate(AB, data, Y, cv=5, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "print('5-fold validation acc:', result_AB['test_score'].mean())\n",
    "result_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vote amount top three classifiers above (AdaBoost, Decision tree, Randon forest)\n",
    "Vote = ensemble.VotingClassifier(estimators=[('AdaBoost', AB), ('Decision Tree', Tree), ('Randon Forest', RF)], n_jobs=-1)\n",
    "Vote.fit(data, Y)\n",
    "\n",
    "# make prediction\n",
    "prediction = Vote.predict(test_data)\n",
    "tmp = pd.read_csv('titanicQuestion.csv')\n",
    "tmp.survived = prediction\n",
    "\n",
    "# write to csv\n",
    "tmp.to_csv('MyPrediciton.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
